# Как работает проект - Полный Workflow

## Общая схема работы

Проект работает в два этапа:

1. **Подготовка** - клонирование репозитория и создание векторной базы
2. **Использование** - разрешение ошибок из stack trace

---

## Этап 1: Подготовка (POST /clone)

### Шаг 1: Клонирование репозитория

```bash
POST /clone
{
  "ssh_url": "git@github.com:user/repo.git",
  "branch": "main"
}
```

**Что происходит:**
- Репозиторий клонируется в `./cloned_repos/{repo_name}/`
- Если репозиторий уже существует, выполняется `git pull` для обновления

### Шаг 2: Индексация Python-файлов

**Модуль:** `agent/indexer.py` → `extract_python_files()`

**Процесс:**
1. Рекурсивно обходит все файлы в репозитории
2. Ищет только `*.py` файлы
3. Игнорирует директории: `.git`, `node_modules`, `venv`, `.idea`, `build`, `__pycache__`, и т.д.
4. Для каждого Python-файла создаёт `Document`:
   ```python
   Document(
       page_content="<содержимое файла>",
       metadata={"path": "filename.py"}
   )
   ```

**Результат:** Список документов LangChain со всеми Python-файлами

### Шаг 3: Создание эмбеддингов

**Модуль:** `agent/vecstore.py` → `create_vector_store()`

**Процесс:**
1. Для каждого документа создаётся эмбеддинг через **OpenRouter API**:
   - Модель: `text-embedding-ada-002` (настраивается через `OPENROUTER_EMBEDDING_MODEL`)
   - API: `https://openrouter.ai/api/v1`
   - Каждый файл преобразуется в вектор (обычно 1536 измерений)

2. Все эмбеддинги сохраняются в **FAISS** векторную базу:
   - FAISS создаёт индекс для быстрого поиска похожих векторов
   - Индекс сохраняется в `./vector_store/`

**Результат:** Векторная база данных FAISS с эмбеддингами всех Python-файлов

---

## Этап 2: Разрешение ошибки (POST /resolve)

### Шаг 1: Парсинг stack trace

**Модуль:** `agent/resolver.py` → `parse_stack_trace()`

```python
# Пример stack trace:
"""
Traceback (most recent call last):
  File "/path/to/file.py", line 42, in function_name
    result = some_function()
  File "/path/to/other_file.py", line 10, in some_function
    return value / 0
ZeroDivisionError: division by zero
"""
```

**Что извлекается:**
- Имена файлов: `file.py`, `other_file.py`
- Номера строк: `42`, `10`

**Результат:**
```python
[
    {"file": "file.py", "line": 42},
    {"file": "other_file.py", "line": 10}
]
```

### Шаг 2: Поиск релевантных документов

**Модуль:** `agent/resolver.py` → `get_relevant_docs()`

**Процесс:**
1. Для каждого файла из stack trace:
   - Используется `vector_store.similarity_search(file_name, k=5)`
   - FAISS ищет 5 наиболее похожих документов по имени файла
   - Поиск основан на векторном сходстве эмбеддингов

2. Все найденные документы объединяются (без дублей)

**Результат:** Список релевантных Python-файлов из кодовой базы

### Шаг 3: Построение контекста

**Модуль:** `agent/resolver.py` → `build_context()`

**Процесс:**
1. Все найденные файлы склеиваются в один большой текст
2. Ограничение: максимум 150,000 токенов (~600,000 символов)
3. Формат:
   ```
   === Файл: file.py ===
   <содержимое файла>
   
   === Файл: other_file.py ===
   <содержимое файла>
   ```

**Результат:** Большой контекст со всеми релевантными файлами

### Шаг 4: Генерация ответа через LLM

**Модуль:** `agent/resolver.py` → `resolve_error()`

**Процесс:**
1. Формируется промпт:
   ```
   Вот ошибка из stack trace:
   <stack trace>
   
   Вот релевантные файлы из кодовой базы:
   <контекст>
   
   Проанализируй ошибку и:
   1. Объясни причину ошибки
   2. Предложи конкретное исправление
   3. Предоставь исправленный код
   ```

2. Отправляется запрос в **OpenRouter API**:
   - Модель: `openai/gpt-3.5-turbo` (настраивается через `OPENROUTER_LLM_MODEL`)
   - API: `https://openrouter.ai/api/v1`
   - LLM анализирует ошибку и контекст кода

3. LLM возвращает объяснение и предложение исправления

**Результат:** Текстовый ответ с объяснением ошибки и предложением исправления

---

## Визуальная схема

```
┌─────────────────────────────────────────────────────────┐
│                    POST /clone                           │
└─────────────────────────────────────────────────────────┘
                        │
                        ▼
        ┌───────────────────────────────┐
        │  1. Клонирование репозитория │
        │     git clone / git pull      │
        └───────────────────────────────┘
                        │
                        ▼
        ┌───────────────────────────────┐
        │  2. Индексация Python-файлов  │
        │     extract_python_files()     │
        │     → List[Document]          │
        └───────────────────────────────┘
                        │
                        ▼
        ┌───────────────────────────────┐
        │  3. Создание эмбеддингов      │
        │     OpenRouter API            │
        │     → Векторы (1536 dim)      │
        └───────────────────────────────┘
                        │
                        ▼
        ┌───────────────────────────────┐
        │  4. Сохранение в FAISS       │
        │     create_vector_store()     │
        │     → ./vector_store/         │
        └───────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│                    POST /resolve                         │
└─────────────────────────────────────────────────────────┘
                        │
                        ▼
        ┌───────────────────────────────┐
        │  1. Парсинг stack trace       │
        │     parse_stack_trace()       │
        │     → [{"file": "...",        │
        │         "line": 42}]          │
        └───────────────────────────────┘
                        │
                        ▼
        ┌───────────────────────────────┐
        │  2. Поиск релевантных файлов  │
        │     similarity_search()       │
        │     FAISS векторный поиск     │
        └───────────────────────────────┘
                        │
                        ▼
        ┌───────────────────────────────┐
        │  3. Построение контекста      │
        │     build_context()           │
        │     → Объединённый текст      │
        └───────────────────────────────┘
                        │
                        ▼
        ┌───────────────────────────────┐
        │  4. Генерация ответа          │
        │     OpenRouter LLM API         │
        │     → Объяснение + исправление│
        └───────────────────────────────┘
```

---

## Пример полного цикла

### 1. Подготовка

```bash
curl -X POST "http://localhost:8000/clone" \
  -H "Content-Type: application/json" \
  -d '{
    "ssh_url": "git@github.com:myuser/myrepo.git",
    "branch": "main"
  }'
```

**Что происходит внутри:**
1. Клонируется `myrepo` → `./cloned_repos/myrepo/`
2. Найдено 50 Python-файлов
3. Создано 50 эмбеддингов через OpenRouter API
4. Сохранено в FAISS → `./vector_store/`

### 2. Использование

```bash
curl -X POST "http://localhost:8000/resolve" \
  -H "Content-Type: application/json" \
  -d '{
    "trace": "Traceback... File \"utils.py\", line 15..."
  }'
```

**Что происходит внутри:**
1. Извлечено: `{"file": "utils.py", "line": 15}`
2. Найдено 5 похожих файлов через FAISS
3. Собран контекст из найденных файлов
4. LLM проанализировал и вернул ответ

---

## Ключевые технологии

- **FAISS** - быстрый векторный поиск (Facebook AI Similarity Search)
- **OpenRouter API** - для эмбеддингов и LLM
- **LangChain** - работа с документами и векторными базами
- **FastAPI** - REST API сервер

## Преимущества подхода

1. **Векторный поиск** - находит релевантные файлы даже если имя не совпадает точно
2. **Контекст** - LLM видит не только проблемный файл, но и связанные файлы
3. **Масштабируемость** - FAISS эффективно работает с большими кодовыми базами
4. **Автоматизация** - весь процесс от клонирования до решения ошибки

